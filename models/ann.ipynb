{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdf4fd6",
   "metadata": {},
   "source": [
    "# Blood-Brain Barrier Permeability Prediction using Artificial Neural Networks\n",
    "\n",
    "This notebook implements an ANN model for predicting blood-brain barrier (BBB) permeability with:\n",
    "- **Hyperparameter Tuning**: Number of layers, neurons per layer, learning rate, batch size\n",
    "- **Wandb Integration**: For visualisation of results and comparison of different models\n",
    "- **Feature Engineering**: Molecular descriptors + MACCS fingerprints as input to model\n",
    "- **Dataset**: B3DB dataset\n",
    "\n",
    "## Table of Contents\n",
    "1. Import Libraries\n",
    "2. Load and Explore Data\n",
    "3. Feature Extraction\n",
    "4. Data Preprocessing\n",
    "5. ANN Model Architecture\n",
    "6. Hyperparameter Tuning with Wandb\n",
    "7. Model Training\n",
    "8. Evaluation and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffbcf78",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578831eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# RDKit for molecular features\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Lipinski, Crippen, MACCSkeys\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                             classification_report, confusion_matrix, roc_curve, auc,\n",
    "                             roc_auc_score, matthews_corrcoef)\n",
    "\n",
    "# Wandb for experiment tracking\n",
    "import wandb\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set style for plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8706fb",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f669e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = Path('../data/BBBP.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(f\"\\nDataset info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['p_np'].value_counts())\n",
    "print(f\"\\nClass balance:\")\n",
    "print(df['p_np'].value_counts(normalize=True))\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67347c82",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction\n",
    "\n",
    "We'll extract two types of features:\n",
    "1. **Molecular Descriptors**: Physical and chemical properties (12 descriptors)\n",
    "2. **MACCS Fingerprints**: 167-bit structural fingerprints\n",
    "\n",
    "Total feature dimension: 12 + 167 = 179 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c40948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_molecular_descriptors(smiles):\n",
    "    \"\"\"Extract molecular descriptors from SMILES string\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    descriptors = {\n",
    "        'MolWt': Descriptors.MolWt(mol),\n",
    "        'LogP': Crippen.MolLogP(mol),\n",
    "        'NumHDonors': Lipinski.NumHDonors(mol),\n",
    "        'NumHAcceptors': Lipinski.NumHAcceptors(mol),\n",
    "        'TPSA': Descriptors.TPSA(mol),\n",
    "        'NumRotatableBonds': Lipinski.NumRotatableBonds(mol),\n",
    "        'NumAromaticRings': Lipinski.NumAromaticRings(mol),\n",
    "        'NumHeteroatoms': Lipinski.NumHeteroatoms(mol),\n",
    "        'NumRings': Lipinski.RingCount(mol),\n",
    "        'FractionCsp3': Lipinski.FractionCSP3(mol),\n",
    "        'NumSaturatedRings': Lipinski.NumSaturatedRings(mol),\n",
    "        'NumAliphaticRings': Lipinski.NumAliphaticRings(mol),\n",
    "    }\n",
    "    return descriptors\n",
    "\n",
    "def extract_maccs_fingerprint(smiles):\n",
    "    \"\"\"Extract MACCS fingerprint from SMILES string\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    maccs = MACCSkeys.GenMACCSKeys(mol)\n",
    "    return np.array(maccs)\n",
    "\n",
    "def extract_features(smiles):\n",
    "    \"\"\"Extract combined features: molecular descriptors + MACCS fingerprints\"\"\"\n",
    "    # Extract descriptors\n",
    "    descriptors = extract_molecular_descriptors(smiles)\n",
    "    if descriptors is None:\n",
    "        return None\n",
    "    \n",
    "    # Extract MACCS fingerprints\n",
    "    maccs = extract_maccs_fingerprint(smiles)\n",
    "    if maccs is None:\n",
    "        return None\n",
    "    \n",
    "    # Combine features\n",
    "    descriptor_values = list(descriptors.values())\n",
    "    combined_features = np.concatenate([descriptor_values, maccs])\n",
    "    \n",
    "    return combined_features\n",
    "\n",
    "print(\"Feature extraction functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6395bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for all molecules\n",
    "print(\"Extracting features from SMILES strings...\")\n",
    "features_list = []\n",
    "valid_indices = []\n",
    "\n",
    "for idx, smiles in enumerate(df['SMILES']):\n",
    "    features = extract_features(smiles)\n",
    "    if features is not None:\n",
    "        features_list.append(features)\n",
    "        valid_indices.append(idx)\n",
    "    \n",
    "    if (idx + 1) % 500 == 0:\n",
    "        print(f\"Processed {idx + 1}/{len(df)} molecules...\")\n",
    "\n",
    "# Convert to numpy array\n",
    "X = np.array(features_list)\n",
    "y = df.loc[valid_indices, 'p_np'].values\n",
    "\n",
    "print(f\"\\nFeature extraction complete!\")\n",
    "print(f\"Total samples: {len(X)}\")\n",
    "print(f\"Feature dimension: {X.shape[1]}\")\n",
    "print(f\"Valid molecules: {len(valid_indices)}/{len(df)}\")\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf138cb0",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing\n",
    "\n",
    "Split the data into training and test sets, then standardize features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af3d0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "# Standardize features (fit on training data only)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nData preprocessing complete!\")\n",
    "print(f\"Scaled training data shape: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled test data shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f1c93",
   "metadata": {},
   "source": [
    "## 5. ANN Model Architecture\n",
    "\n",
    "Define a flexible neural network architecture that supports variable number of layers and neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843a433",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBBPredictorANN(nn.Module):\n",
    "    \"\"\"\n",
    "    Flexible ANN architecture for BBB permeability prediction\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_size : int\n",
    "        Dimension of input features\n",
    "    hidden_layers : list of int\n",
    "        Number of neurons in each hidden layer\n",
    "    dropout_rate : float\n",
    "        Dropout rate for regularization\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_layers, dropout_rate=0.3):\n",
    "        super(BBBPredictorANN, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        # Build hidden layers\n",
    "        for hidden_size in hidden_layers:\n",
    "            layers.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.BatchNorm1d(hidden_size))\n",
    "            layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Output layer (binary classification)\n",
    "        layers.append(nn.Linear(prev_size, 1))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "print(\"ANN model class defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82de602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    \"\"\"Train the ANN model and track performance\"\"\"\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y.unsqueeze(1))\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            train_correct += (predictions == batch_y.unsqueeze(1)).sum().item()\n",
    "            train_total += batch_y.size(0)\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Calculate average training loss and accuracy\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_correct / train_total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                \n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y.unsqueeze(1))\n",
    "                \n",
    "                predictions = (outputs > 0.5).float()\n",
    "                val_correct += (predictions == batch_y.unsqueeze(1)).sum().item()\n",
    "                val_total += batch_y.size(0)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        # Calculate average validation loss and accuracy\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        # Log to wandb\n",
    "        wandb.log({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'train_accuracy': train_acc,\n",
    "            'val_accuracy': val_acc\n",
    "        })\n",
    "        \n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "                  f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f} - \"\n",
    "                  f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'val_accs': val_accs,\n",
    "        'best_val_acc': best_val_acc\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate the model on test set\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            outputs = model(batch_X)\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(batch_y.cpu().numpy())\n",
    "            all_probs.extend(outputs.cpu().numpy())\n",
    "    \n",
    "    all_predictions = np.array(all_predictions).flatten()\n",
    "    all_labels = np.array(all_labels).flatten()\n",
    "    all_probs = np.array(all_probs).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions)\n",
    "    recall = recall_score(all_labels, all_predictions)\n",
    "    f1 = f1_score(all_labels, all_predictions)\n",
    "    roc_auc = roc_auc_score(all_labels, all_probs)\n",
    "    mcc = matthews_corrcoef(all_labels, all_predictions)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'mcc': mcc\n",
    "    }\n",
    "    \n",
    "    return metrics, all_predictions, all_labels, all_probs\n",
    "\n",
    "print(\"Training and evaluation functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c944a88",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning with Wandb\n",
    "\n",
    "We'll tune the following hyperparameters:\n",
    "- **Number of hidden layers**: 2, 3, 4\n",
    "- **Neurons per layer**: 64, 128, 256\n",
    "- **Learning rate**: 0.0001, 0.001, 0.01\n",
    "- **Batch size**: 16, 32, 64\n",
    "- **Dropout rate**: 0.2, 0.3, 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39439b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter search space\n",
    "hyperparameter_configs = [\n",
    "    # Configuration 1: 2 layers, 128 neurons\n",
    "    {'num_layers': 2, 'neurons': 128, 'learning_rate': 0.001, 'batch_size': 32, 'dropout': 0.3},\n",
    "    # Configuration 2: 3 layers, 128 neurons\n",
    "    {'num_layers': 3, 'neurons': 128, 'learning_rate': 0.001, 'batch_size': 32, 'dropout': 0.3},\n",
    "    # Configuration 3: 2 layers, 256 neurons\n",
    "    {'num_layers': 2, 'neurons': 256, 'learning_rate': 0.001, 'batch_size': 32, 'dropout': 0.3},\n",
    "    # Configuration 4: 3 layers, 64 neurons\n",
    "    {'num_layers': 3, 'neurons': 64, 'learning_rate': 0.001, 'batch_size': 32, 'dropout': 0.3},\n",
    "    # Configuration 5: 2 layers, 128 neurons, higher lr\n",
    "    {'num_layers': 2, 'neurons': 128, 'learning_rate': 0.01, 'batch_size': 32, 'dropout': 0.3},\n",
    "    # Configuration 6: 2 layers, 128 neurons, lower lr\n",
    "    {'num_layers': 2, 'neurons': 128, 'learning_rate': 0.0001, 'batch_size': 32, 'dropout': 0.3},\n",
    "    # Configuration 7: 2 layers, 128 neurons, larger batch\n",
    "    {'num_layers': 2, 'neurons': 128, 'learning_rate': 0.001, 'batch_size': 64, 'dropout': 0.3},\n",
    "    # Configuration 8: 2 layers, 128 neurons, smaller batch\n",
    "    {'num_layers': 2, 'neurons': 128, 'learning_rate': 0.001, 'batch_size': 16, 'dropout': 0.3},\n",
    "    # Configuration 9: 3 layers, 256 neurons\n",
    "    {'num_layers': 3, 'neurons': 256, 'learning_rate': 0.001, 'batch_size': 32, 'dropout': 0.3},\n",
    "    # Configuration 10: 4 layers, 128 neurons\n",
    "    {'num_layers': 4, 'neurons': 128, 'learning_rate': 0.001, 'batch_size': 32, 'dropout': 0.3},\n",
    "    # Configuration 11: 2 layers, 128 neurons, higher dropout\n",
    "    {'num_layers': 2, 'neurons': 128, 'learning_rate': 0.001, 'batch_size': 32, 'dropout': 0.4},\n",
    "    # Configuration 12: 2 layers, 128 neurons, lower dropout\n",
    "    {'num_layers': 2, 'neurons': 128, 'learning_rate': 0.001, 'batch_size': 32, 'dropout': 0.2},\n",
    "]\n",
    "\n",
    "print(f\"Total hyperparameter configurations: {len(hyperparameter_configs)}\")\n",
    "print(\"\\nSample configurations:\")\n",
    "for i, config in enumerate(hyperparameter_configs[:3]):\n",
    "    print(f\"Config {i+1}: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b4b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(config, X_train, y_train, X_test, y_test, input_size, num_epochs=100):\n",
    "    \"\"\"\n",
    "    Run a single experiment with given hyperparameters\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    config : dict\n",
    "        Hyperparameter configuration\n",
    "    X_train, y_train : numpy arrays\n",
    "        Training data\n",
    "    X_test, y_test : numpy arrays\n",
    "        Test data\n",
    "    input_size : int\n",
    "        Input feature dimension\n",
    "    num_epochs : int\n",
    "        Number of training epochs\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    metrics : dict\n",
    "        Test set performance metrics\n",
    "    \"\"\"\n",
    "    # Initialize wandb run\n",
    "    run = wandb.init(\n",
    "        project=\"bbb-permeability-ann\",\n",
    "        config=config,\n",
    "        reinit=True\n",
    "    )\n",
    "    \n",
    "    # Split training data into train and validation sets\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.FloatTensor(X_tr),\n",
    "        torch.FloatTensor(y_tr)\n",
    "    )\n",
    "    val_dataset = TensorDataset(\n",
    "        torch.FloatTensor(X_val),\n",
    "        torch.FloatTensor(y_val)\n",
    "    )\n",
    "    test_dataset = TensorDataset(\n",
    "        torch.FloatTensor(X_test),\n",
    "        torch.FloatTensor(y_test)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "    \n",
    "    # Create model\n",
    "    hidden_layers = [config['neurons']] * config['num_layers']\n",
    "    model = BBBPredictorANN(\n",
    "        input_size=input_size,\n",
    "        hidden_layers=hidden_layers,\n",
    "        dropout_rate=config['dropout']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\nTraining with config: {config}\")\n",
    "    model, history = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, num_epochs, device\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    metrics, predictions, labels, probs = evaluate_model(model, test_loader, device)\n",
    "    \n",
    "    # Log final metrics to wandb\n",
    "    wandb.log({\n",
    "        'test_accuracy': metrics['accuracy'],\n",
    "        'test_precision': metrics['precision'],\n",
    "        'test_recall': metrics['recall'],\n",
    "        'test_f1_score': metrics['f1_score'],\n",
    "        'test_roc_auc': metrics['roc_auc'],\n",
    "        'test_mcc': metrics['mcc']\n",
    "    })\n",
    "    \n",
    "    # Log confusion matrix\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    wandb.log({\n",
    "        \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "            probs=None,\n",
    "            y_true=labels.astype(int),\n",
    "            preds=predictions.astype(int),\n",
    "            class_names=[\"Non-permeable\", \"Permeable\"]\n",
    "        )\n",
    "    })\n",
    "    \n",
    "    print(f\"Test Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Test F1-Score: {metrics['f1_score']:.4f}\")\n",
    "    print(f\"Test ROC-AUC: {metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    run.finish()\n",
    "    \n",
    "    return metrics, model, history\n",
    "\n",
    "print(\"Experiment function defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d031e0",
   "metadata": {},
   "source": [
    "## 7. Run Hyperparameter Tuning Experiments\n",
    "\n",
    "Now we'll run all hyperparameter configurations and track results with Wandb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5401bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run hyperparameter tuning experiments\n",
    "# Note: Set to smaller number of configs for faster testing\n",
    "# To run all configs, use: configs_to_run = hyperparameter_configs\n",
    "\n",
    "# For demonstration, we'll run first 3 configs (you can change this)\n",
    "configs_to_run = hyperparameter_configs[:3]  # Change to hyperparameter_configs for all\n",
    "\n",
    "input_size = X_train_scaled.shape[1]\n",
    "num_epochs = 100\n",
    "\n",
    "results = []\n",
    "best_f1 = 0\n",
    "best_config = None\n",
    "best_model = None\n",
    "\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "print(f\"Total configurations to test: {len(configs_to_run)}\\n\")\n",
    "\n",
    "for i, config in enumerate(configs_to_run):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Experiment {i+1}/{len(configs_to_run)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    metrics, model, history = run_experiment(\n",
    "        config=config,\n",
    "        X_train=X_train_scaled,\n",
    "        y_train=y_train,\n",
    "        X_test=X_test_scaled,\n",
    "        y_test=y_test,\n",
    "        input_size=input_size,\n",
    "        num_epochs=num_epochs\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    result = {**config, **metrics}\n",
    "    results.append(result)\n",
    "    \n",
    "    # Track best model\n",
    "    if metrics['f1_score'] > best_f1:\n",
    "        best_f1 = metrics['f1_score']\n",
    "        best_config = config\n",
    "        best_model = model\n",
    "    \n",
    "    print(f\"\\nCurrent best F1-score: {best_f1:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Hyperparameter tuning complete!\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18aa630",
   "metadata": {},
   "source": [
    "## 8. Results Analysis\n",
    "\n",
    "Let's analyze the results from all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by F1-score\n",
    "results_df_sorted = results_df.sort_values('f1_score', ascending=False)\n",
    "\n",
    "print(\"Top 5 configurations by F1-score:\")\n",
    "print(results_df_sorted.head())\n",
    "\n",
    "print(f\"\\n\\nBest Configuration:\")\n",
    "print(f\"{'='*60}\")\n",
    "for key, value in best_config.items():\n",
    "    print(f\"{key:20s}: {value}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Best F1-score: {best_f1:.4f}\")\n",
    "\n",
    "# Save results to CSV\n",
    "results_path = Path('../figures/BBBP/')\n",
    "results_path.mkdir(parents=True, exist_ok=True)\n",
    "results_df_sorted.to_csv(results_path / 'ann_hyperparameter_results.csv', index=False)\n",
    "print(f\"\\nResults saved to {results_path / 'ann_hyperparameter_results.csv'}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
